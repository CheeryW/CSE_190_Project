{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "wk-AIFjqrQwE",
    "outputId": "5a6d4586-49ef-456f-9b33-9913b4da683e"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "import pickle\n",
    "from music21 import *\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Lambda\n",
    "from keras.layers import LSTM, Bidirectional\n",
    "from keras.layers import Activation\n",
    "from keras.layers import BatchNormalization as BatchNorm\n",
    "from keras.utils import np_utils\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import random\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ILc_9On7ob1-"
   },
   "outputs": [],
   "source": [
    "def create_network(network_input, n_vocab):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(\n",
    "        512,\n",
    "        input_shape=(network_input.shape[1], network_input.shape[2]),\n",
    "        recurrent_dropout=0.3,\n",
    "        return_sequences=True\n",
    "    ))\n",
    "    \n",
    "    model.add(LSTM(\n",
    "        512, \n",
    "        recurrent_dropout=0.3,\n",
    "        return_sequences=False\n",
    "    ))\n",
    "    \n",
    "    model.add(BatchNorm())\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(256))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(BatchNorm())\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(n_vocab))\n",
    "    model.add(Lambda(lambda x: x / 0.6))\n",
    "    model.add(Activation('softmax'))\n",
    "\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Cm4LKeyNZjA8"
   },
   "outputs": [],
   "source": [
    "def prepare_sequences_homework(notes, n_vocab, debug = False):\n",
    "    #Prepare the sequences used by the Neural Network\n",
    "    sequence_length = 4\n",
    "\n",
    "    pitchnames = sorted(set(item for item in notes))\n",
    "\n",
    "    note_to_int = dict((note, number) for number, note in enumerate(pitchnames))\n",
    "\n",
    "    network_input = []\n",
    "    network_output = []\n",
    "\n",
    "    for i in range(0, len(notes) - sequence_length, 1):\n",
    "        sequence_in = notes[i:i + sequence_length]\n",
    "        sequence_out = notes[i + sequence_length]\n",
    "        if debug:\n",
    "            network_input.append(sequence_in)\n",
    "            network_output.append(sequence_out)\n",
    "        else:\n",
    "            network_input.append([note_to_int[char] for char in sequence_in])\n",
    "            network_output.append(note_to_int[sequence_out])\n",
    "\n",
    "    n_patterns = len(network_input)\n",
    "\n",
    "    # reshape the input into a format compatible with LSTM layers\n",
    "    network_input = np.reshape(network_input, (n_patterns, sequence_length, 1))\n",
    "    # normalize input\n",
    "    if debug == False:\n",
    "        network_input = network_input / float(n_vocab)\n",
    "        network_output = np_utils.to_categorical(network_output)\n",
    "\n",
    "    return (network_input, network_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uBoEpvhra8b2"
   },
   "outputs": [],
   "source": [
    "# Looping works in this cell\n",
    "def get_notes():\n",
    "\n",
    "    notes = []\n",
    "    filesAdded = 0\n",
    "    for file in glob.glob(\"midiFiles/*.mid\"):\n",
    "        midi = converter.parse(file)\n",
    "        print(\"Parsing %s\" % file)\n",
    "        notes_to_parse = None\n",
    "        try: # file has instrument parts\n",
    "            s2 = instrument.partitionByInstrument(midi)\n",
    "            notes_to_parse = s2.parts[0].recurse() \n",
    "        except: # file has notes in a flat structure\n",
    "            notes_to_parse = midi.flat.notes\n",
    "\n",
    "        for element in notes_to_parse:\n",
    "            if isinstance(element, note.Note):\n",
    "                notes.append(str(element.pitch))\n",
    "            elif isinstance(element, chord.Chord):\n",
    "                notes.append('.'.join(str(n) for n in element.normalOrder))\n",
    "        notes.append('$')\n",
    "        \n",
    "        filesAdded += 1\n",
    "        \"\"\" Stop after n files\"\"\"\n",
    "        #if filesAdded == 2:\n",
    "        #    break\n",
    "\n",
    "    pickle.dump(notes, open('notes.p', 'wb'))\n",
    "\n",
    "    return notes\n",
    "\n",
    "def prepare_sequences_homework(notes, n_vocab, debug = False):\n",
    "    #Prepare the sequences used by the Neural Network\n",
    "    sequence_length = 4\n",
    "\n",
    "    pitchnames = sorted(set(item for item in notes))\n",
    "\n",
    "    note_to_int = dict((note, number) for number, note in enumerate(pitchnames))\n",
    "\n",
    "    network_input = []\n",
    "    network_output = []\n",
    "\n",
    "    for i in range(0, len(notes) - sequence_length, 1):\n",
    "        sequence_in = notes[i:i + sequence_length]\n",
    "        sequence_out = notes[i + sequence_length]\n",
    "        if debug:\n",
    "            network_input.append(sequence_in)\n",
    "            network_output.append(sequence_out)\n",
    "        else:\n",
    "            network_input.append([note_to_int[char] for char in sequence_in])\n",
    "            network_output.append(note_to_int[sequence_out])\n",
    "\n",
    "    n_patterns = len(network_input)\n",
    "\n",
    "    # reshape the input into a format compatible with LSTM layers\n",
    "    network_input = np.reshape(network_input, (n_patterns, sequence_length, 1))\n",
    "    # normalize input\n",
    "    if debug == False:\n",
    "        network_input = network_input / float(n_vocab)\n",
    "        network_output = np_utils.to_categorical(network_output)\n",
    "\n",
    "    return (network_input, network_output)\n",
    "\n",
    "def prepare_sequences(notes, n_vocab, debug=False):\n",
    "    \"\"\" Prepare the sequences used by the Neural Network \"\"\"\n",
    "    sequence_length = 4\n",
    "\n",
    "    pitchnames = sorted(set(item for item in notes))\n",
    "    #print(pitchnames)\n",
    "\n",
    "    note_to_int = dict((note, number) for number, note in enumerate(pitchnames))\n",
    "    #print(note_to_int)\n",
    "    network_input = []\n",
    "    network_output = []\n",
    "    first_note_of_file = 0\n",
    "    midi_start_index = 0\n",
    "    \"\"\" Our implementation \"\"\"\n",
    "    for i in range(0, len(notes) - sequence_length, 1):\n",
    "        if '$' in notes[i:i+sequence_length]:\n",
    "            continue\n",
    "        output_note = i + sequence_length\n",
    "        output_char = notes[i + sequence_length]\n",
    "        if output_char == '$':\n",
    "            i_copy = i\n",
    "            for k in range(sequence_length):\n",
    "                sequence_in = notes[i_copy:output_note] + notes[midi_start_index:midi_start_index+(k)]\n",
    "                sequence_out = notes[first_note_of_file]\n",
    "                if debug:\n",
    "                  network_input.append(sequence_in)\n",
    "                  network_output.append(sequence_out)\n",
    "                else:  \n",
    "                  network_input.append([note_to_int[char] for char in sequence_in])\n",
    "                  network_output.append(note_to_int[sequence_out])\n",
    "                first_note_of_file += 1\n",
    "                i_copy += 1\n",
    "            midi_start_index = output_note + 1\n",
    "            i = midi_start_index\n",
    "            #print(i)\n",
    "            first_note_of_file = midi_start_index\n",
    "        else:\n",
    "            sequence_in = notes[i:i + sequence_length]\n",
    "            sequence_out = notes[i + sequence_length]\n",
    "            if debug:\n",
    "              network_input.append(sequence_in)\n",
    "              network_output.append(sequence_out)\n",
    "            else:  \n",
    "              network_input.append([note_to_int[char] for char in sequence_in])\n",
    "              network_output.append(note_to_int[sequence_out])\n",
    "    \n",
    "    n_patterns = len(network_input)\n",
    "\n",
    "    # reshape the input into a format compatible with LSTM layers\n",
    "    network_input = np.reshape(network_input, (n_patterns, sequence_length, 1))\n",
    "    # normalize input\n",
    "    if debug == False:\n",
    "      network_input = network_input / float(n_vocab)\n",
    "      network_output = np_utils.to_categorical(network_output)\n",
    "\n",
    "    return (network_input, network_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "dgNJZ5b-Teue",
    "outputId": "63628144-23b5-4d30-e967-a433ff339eb2"
   },
   "outputs": [],
   "source": [
    "custom_input = ['A','B','C','D','E','F','G','$','p','q','r','s','t','u','v','$']\n",
    "b,c = prepare_sequences_homework(custom_input,len(set(custom_input)),debug=True)\n",
    "print(\"HOMEWORK IMPLEMENTATION\")\n",
    "for i in range(len(b)):\n",
    "  print(b[i],c[i])\n",
    "print(\"OUR IMPLEMENTATION\")\n",
    "b,c = prepare_sequences(custom_input,len(set(custom_input)),debug=True)\n",
    "for i in range(len(b)):\n",
    "  print(b[i],c[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 374
    },
    "colab_type": "code",
    "id": "P3rV2u67pwas",
    "outputId": "be4900c4-5e76-458a-cb0a-32c1b8aa4d71"
   },
   "outputs": [],
   "source": [
    "def train_network():\n",
    "    \"\"\" Train a Neural Network to generate music \"\"\"\n",
    "    notes = get_notes()\n",
    "\n",
    "    n_vocab = len(set(notes))\n",
    "    \n",
    "    network_input, network_output = prepare_sequences(notes, n_vocab)\n",
    "    \n",
    "    model = create_network(network_input, n_vocab)\n",
    " \n",
    "    checkpoint = ModelCheckpoint(\n",
    "        \"weights.hdf5\",\n",
    "        monitor='loss',\n",
    "        verbose=0,\n",
    "        save_best_only=True,\n",
    "        mode='min'\n",
    "    )\n",
    "    \n",
    "    callbacks_list = [checkpoint]\n",
    "\n",
    "    # Your line of code here\n",
    "    model.fit(x=network_input, y=network_output, epochs=50, batch_size = 8, callbacks=callbacks_list)\n",
    "    \n",
    "train_network()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "a7aBjephqznI"
   },
   "outputs": [],
   "source": [
    "def prepare_sequences_prediction(notes, pitchnames, n_vocab):\n",
    "\n",
    "    note_to_int = dict((note, number) for number, note in enumerate(pitchnames))\n",
    "    sequence_length = 8\n",
    "    network_input = []\n",
    "    output = []\n",
    "    for i in range(0, len(notes) - sequence_length, 1):\n",
    "        sequence_in = notes[i:i + sequence_length]\n",
    "        sequence_out = notes[i + sequence_length]\n",
    "        network_input.append([note_to_int[char] for char in sequence_in])\n",
    "        output.append(note_to_int[sequence_out])\n",
    "\n",
    "    n_patterns = len(network_input)\n",
    "\n",
    "    # reshape the input into a format compatible with LSTM layers\n",
    "    normalized_input = np.reshape(network_input, (n_patterns, sequence_length, 1))\n",
    "    # normalize input\n",
    "    normalized_input = normalized_input / float(n_vocab)\n",
    "\n",
    "    return (network_input, normalized_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QbRcSMXZrQK8"
   },
   "outputs": [],
   "source": [
    "def generate_notes(model, network_input, pitchnames, n_vocab):\n",
    "    \"\"\" Generate notes from the neural network based on a sequence of notes \"\"\"\n",
    "    # Starts the melody by picking a random sequence from the input as a starting point\n",
    "    start = np.random.randint(0, len(network_input)-1)\n",
    "\n",
    "    int_to_note = dict((number, note) for number, note in enumerate(pitchnames))\n",
    "\n",
    "    pattern = network_input[start]\n",
    "    prediction_output = []\n",
    "\n",
    "    for note_index in range(200):\n",
    "        prediction_input = np.reshape(pattern, (1, len(pattern), 1))\n",
    "        prediction_input = prediction_input / float(n_vocab)\n",
    "        \n",
    "        ### Complete the line below\n",
    "        prediction = model.predict(prediction_input)\n",
    "        prob = (prediction / np.sum(prediction))[0]\n",
    "        \n",
    "        index = random.choices(list(range(len(prob))), weights=prob)[0]\n",
    "        result = int_to_note[index]\n",
    "        prediction_output.append(result)\n",
    "\n",
    "        pattern.append(index)\n",
    "        pattern = pattern[1:len(pattern)]\n",
    "\n",
    "    return prediction_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6m-pmW7arSGJ"
   },
   "outputs": [],
   "source": [
    "def generate():\n",
    "    notes = pickle.load(open('notes.p', 'rb'))\n",
    "    pitchnames = sorted(set(item for item in notes))\n",
    "    n_vocab = len(set(notes))\n",
    "\n",
    "    network_input, normalized_input = prepare_sequences_prediction(notes, pitchnames, n_vocab)\n",
    "    model = create_network(normalized_input, n_vocab)\n",
    "    \n",
    "    # TODO: Change hdf5 file name later\n",
    "    model.load_weights(\"weights.hdf5\")\n",
    "    \n",
    "    prediction_output = generate_notes(model, network_input, pitchnames, n_vocab)\n",
    "    create_midi(prediction_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 316
    },
    "colab_type": "code",
    "id": "2ARsuPyBrTif",
    "outputId": "4e5bf2a9-75b0-4c7f-ee4b-800dfa0279c8"
   },
   "outputs": [],
   "source": [
    "def create_midi(prediction_output):\n",
    "    offset = 0\n",
    "    output_notes = []\n",
    "    for pattern in prediction_output:\n",
    "        if ('.' in pattern) or pattern.isdigit():\n",
    "            notes_in_chord = pattern.split('.')\n",
    "            notes = []\n",
    "            for current_note in notes_in_chord:\n",
    "                new_note = note.Note(int(current_note))\n",
    "                new_note.storedInstrument = instrument.Piano()\n",
    "                notes.append(new_note)\n",
    "            new_chord = chord.Chord(notes)\n",
    "            new_chord.offset = offset\n",
    "            output_notes.append(new_chord)\n",
    "        else:\n",
    "            new_note = note.Note(pattern)\n",
    "            new_note.offset = offset\n",
    "            new_note.storedInstrument = instrument.Piano()\n",
    "            output_notes.append(new_note)\n",
    "        offset += 1.0\n",
    "\n",
    "    print(output_notes)    \n",
    "    midi_stream = stream.Stream(output_notes)\n",
    "    midi_stream.write('midi', fp='test_output.mid')\n",
    "    \n",
    "generate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "colab_type": "code",
    "id": "FiY7_2dBrqwo",
    "outputId": "0bb675d3-83af-4f57-dccf-e20f24cf45ae"
   },
   "outputs": [],
   "source": [
    "mf = midi.MidiFile()\n",
    "mf.open(\"test_output.mid\")\n",
    "mf.read()\n",
    "mf.close()\n",
    "s = midi.translate.midiFileToStream(mf)\n",
    "myStream = stream.Stream()\n",
    "myStream.append(s)\n",
    "\n",
    "x = myStream\n",
    "x.show('midi')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "CSE190_Project.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
